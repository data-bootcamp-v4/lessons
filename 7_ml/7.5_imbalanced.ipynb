{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imbalanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imbalance data refers to a situation in which the classes within the dataset are not represented equally.\n",
        "\n",
        "**Is a classification problem that affects the target variable.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading and preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sJ2LeEdzAKXQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "0              1         0       3   \n",
              "1              2         1       1   \n",
              "2              3         1       3   \n",
              "3              4         1       1   \n",
              "4              5         0       3   \n",
              "..           ...       ...     ...   \n",
              "886          887         0       2   \n",
              "887          888         1       1   \n",
              "888          889         0       3   \n",
              "889          890         1       1   \n",
              "890          891         0       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                             Allen, Mr. William Henry    male  35.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
              "\n",
              "     Parch            Ticket     Fare Cabin Embarked  \n",
              "0        0         A/5 21171   7.2500   NaN        S  \n",
              "1        0          PC 17599  71.2833   C85        C  \n",
              "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3        0            113803  53.1000  C123        S  \n",
              "4        0            373450   8.0500   NaN        S  \n",
              "..     ...               ...      ...   ...      ...  \n",
              "886      0            211536  13.0000   NaN        S  \n",
              "887      0            112053  30.0000   B42        S  \n",
              "888      2        W./C. 6607  23.4500   NaN        S  \n",
              "889      0            111369  30.0000  C148        C  \n",
              "890      0            370376   7.7500   NaN        Q  \n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titanic = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/titanic_train.csv\")\n",
        "titanic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Check for anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titanic.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upon checking the number of null values, we are going to drop the column **Cabin** and also dropping rows where **Age** is null."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic.drop(columns=\"Cabin\", inplace = True)\n",
        "titanic.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(712, 11)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titanic.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "survived = titanic[\"Survived\"].value_counts()\n",
        "survived.plot(kind=\"bar\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Preparing the data before modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic.drop(columns=[\"Name\", \"Ticket\", \"PassengerId\"], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic[\"Sex\"] = titanic[\"Sex\"].replace({\"male\":0,\n",
        "                                         \"female\":1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic = pd.get_dummies(titanic, columns=[\"Embarked\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n",
              "0         0       3    0  22.0      1      0   7.2500           0           0   \n",
              "1         1       1    1  38.0      1      0  71.2833           1           0   \n",
              "2         1       3    1  26.0      0      0   7.9250           0           0   \n",
              "3         1       1    1  35.0      1      0  53.1000           0           0   \n",
              "4         0       3    0  35.0      0      0   8.0500           0           0   \n",
              "\n",
              "   Embarked_S  \n",
              "0           1  \n",
              "1           0  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titanic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For baseline, we will train a Logistic Regression in imbalanced data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = titanic.drop(columns = [\"Survived\"])\n",
        "target = titanic[\"Survived\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_reg = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_reg.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8314606741573034"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_reg.score(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86       104\n",
            "           1       0.83      0.74      0.79        74\n",
            "\n",
            "    accuracy                           0.83       178\n",
            "   macro avg       0.83      0.82      0.82       178\n",
            "weighted avg       0.83      0.83      0.83       178\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = log_reg.predict(X_test_scaled)\n",
        "print(classification_report(y_pred = pred, y_true = y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.DataFrame(X_train_scaled, columns = X_train.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train[\"Survived\"] = y_train.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "survived = train[train[\"Survived\"] == 1]\n",
        "no_survived = train[train[\"Survived\"] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "yes_diabetes_oversampled = resample(survived, \n",
        "                                    replace=True, \n",
        "                                    n_samples = len(no_survived),\n",
        "                                    random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>0.457405</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>0.661839</td>\n",
              "      <td>8.572376</td>\n",
              "      <td>2.149663</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>-1.877611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.310087</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.485413</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>-0.314064</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-0.798490</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>0.661839</td>\n",
              "      <td>-0.212092</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>0.038773</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.401038</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>-0.314064</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>0.178317</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.391613</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.030999</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.086428</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.379859</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.490425</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>2.411019</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>4.184318</td>\n",
              "      <td>4.096403</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>0.248089</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.485413</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-0.658946</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.448611</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>640 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pclass       Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
              "414 -1.520614 -0.752318  0.457405 -0.554683  0.661839  8.572376    2.149663   \n",
              "122  0.892485 -0.752318 -0.310087  0.503177 -0.512321 -0.485413   -0.465189   \n",
              "267 -0.314064  1.329225 -0.798490 -0.554683  0.661839 -0.212092   -0.465189   \n",
              "480  0.892485  1.329225  0.038773 -0.554683 -0.512321 -0.401038   -0.465189   \n",
              "155 -0.314064  1.329225  0.178317 -0.554683 -0.512321 -0.391613   -0.465189   \n",
              "..        ...       ...       ...       ...       ...       ...         ...   \n",
              "524 -1.520614 -0.752318 -0.030999 -0.554683 -0.512321 -0.086428   -0.465189   \n",
              "528  0.892485 -0.752318 -0.379859 -0.554683 -0.512321 -0.490425   -0.465189   \n",
              "529 -1.520614 -0.752318  2.411019  0.503177  4.184318  4.096403   -0.465189   \n",
              "530  0.892485 -0.752318  0.248089 -0.554683 -0.512321 -0.485413   -0.465189   \n",
              "533  0.892485  1.329225 -0.658946  0.503177 -0.512321 -0.448611   -0.465189   \n",
              "\n",
              "     Embarked_Q  Embarked_S  Survived  \n",
              "414   -0.212155   -1.877611         1  \n",
              "122   -0.212155    0.532592         1  \n",
              "267   -0.212155    0.532592         1  \n",
              "480   -0.212155    0.532592         1  \n",
              "155   -0.212155    0.532592         1  \n",
              "..          ...         ...       ...  \n",
              "524   -0.212155    0.532592         0  \n",
              "528   -0.212155    0.532592         0  \n",
              "529   -0.212155    0.532592         0  \n",
              "530   -0.212155    0.532592         0  \n",
              "533   -0.212155    0.532592         0  \n",
              "\n",
              "[640 rows x 10 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_over = pd.concat([yes_diabetes_oversampled, no_survived])\n",
        "train_over"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "survived_plt = train_over[\"Survived\"].value_counts()\n",
        "survived_plt.plot(kind=\"bar\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, with balanced data, we will create a new instance of Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_over = train_over.drop(columns = [\"Survived\"])\n",
        "y_train_over = train_over[\"Survived\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_over, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.82       104\n",
            "           1       0.74      0.76      0.75        74\n",
            "\n",
            "    accuracy                           0.79       178\n",
            "   macro avg       0.78      0.78      0.78       178\n",
            "weighted avg       0.79      0.79      0.79       178\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\frede\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pred = log_reg.predict(X_test_scaled)\n",
        "print(classification_report(y_pred = pred, y_true = y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Undersampling involves removing data points from the majority class to align its size with that of the minority class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.589174</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.469480</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-0.798490</td>\n",
              "      <td>1.561036</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.301853</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.938034</td>\n",
              "      <td>1.561036</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.301853</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.314064</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.030999</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.247997</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.030999</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.454445</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>2.411019</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>4.184318</td>\n",
              "      <td>4.096403</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>0.248089</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.485413</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>1.503984</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.148363</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>-0.314064</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-1.845069</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>1.835999</td>\n",
              "      <td>0.121442</td>\n",
              "      <td>2.149663</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>-1.877611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-0.658946</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.448611</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>534 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pclass       Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
              "0    0.892485 -0.752318 -0.589174 -0.554683 -0.512321 -0.469480   -0.465189   \n",
              "1    0.892485  1.329225 -0.798490  1.561036 -0.512321 -0.301853   -0.465189   \n",
              "2    0.892485 -0.752318 -0.938034  1.561036 -0.512321 -0.301853   -0.465189   \n",
              "3   -0.314064 -0.752318 -0.030999  0.503177 -0.512321 -0.247997   -0.465189   \n",
              "4    0.892485 -0.752318 -0.030999 -0.554683 -0.512321 -0.454445   -0.465189   \n",
              "..        ...       ...       ...       ...       ...       ...         ...   \n",
              "529 -1.520614 -0.752318  2.411019  0.503177  4.184318  4.096403   -0.465189   \n",
              "530  0.892485 -0.752318  0.248089 -0.554683 -0.512321 -0.485413   -0.465189   \n",
              "531 -1.520614 -0.752318  1.503984 -0.554683 -0.512321 -0.148363   -0.465189   \n",
              "532 -0.314064  1.329225 -1.845069  0.503177  1.835999  0.121442    2.149663   \n",
              "533  0.892485  1.329225 -0.658946  0.503177 -0.512321 -0.448611   -0.465189   \n",
              "\n",
              "     Embarked_Q  Embarked_S  Survived  \n",
              "0     -0.212155    0.532592         0  \n",
              "1     -0.212155    0.532592         0  \n",
              "2     -0.212155    0.532592         0  \n",
              "3     -0.212155    0.532592         0  \n",
              "4     -0.212155    0.532592         1  \n",
              "..          ...         ...       ...  \n",
              "529   -0.212155    0.532592         0  \n",
              "530   -0.212155    0.532592         0  \n",
              "531   -0.212155    0.532592         1  \n",
              "532   -0.212155   -1.877611         1  \n",
              "533   -0.212155    0.532592         0  \n",
              "\n",
              "[534 rows x 10 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>2.131931</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.148363</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-0.798490</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.485413</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>0.806264</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>5.358478</td>\n",
              "      <td>0.087483</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>0.178317</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.482720</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.100771</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.483244</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>0.108545</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.301853</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>-0.314064</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.798490</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.418541</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-1.914841</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>1.835999</td>\n",
              "      <td>2.095645</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.798490</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.475988</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-0.589174</td>\n",
              "      <td>1.561036</td>\n",
              "      <td>1.835999</td>\n",
              "      <td>-0.007888</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>214 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pclass       Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
              "315 -1.520614 -0.752318  2.131931 -0.554683 -0.512321 -0.148363   -0.465189   \n",
              "440  0.892485  1.329225 -0.798490 -0.554683 -0.512321 -0.485413   -0.465189   \n",
              "25   0.892485  1.329225  0.806264 -0.554683  5.358478  0.087483   -0.465189   \n",
              "109  0.892485 -0.752318  0.178317 -0.554683 -0.512321 -0.482720   -0.465189   \n",
              "373  0.892485 -0.752318 -0.100771 -0.554683 -0.512321 -0.483244   -0.465189   \n",
              "..        ...       ...       ...       ...       ...       ...         ...   \n",
              "236  0.892485  1.329225  0.108545  0.503177 -0.512321 -0.301853   -0.465189   \n",
              "325 -0.314064 -0.752318 -0.798490 -0.554683 -0.512321 -0.418541   -0.465189   \n",
              "422 -1.520614  1.329225 -1.914841  0.503177  1.835999  2.095645   -0.465189   \n",
              "377  0.892485 -0.752318 -0.798490 -0.554683 -0.512321 -0.475988   -0.465189   \n",
              "423  0.892485  1.329225 -0.589174  1.561036  1.835999 -0.007888   -0.465189   \n",
              "\n",
              "     Embarked_Q  Embarked_S  Survived  \n",
              "315   -0.212155    0.532592         0  \n",
              "440   -0.212155    0.532592         0  \n",
              "25    -0.212155    0.532592         0  \n",
              "109   -0.212155    0.532592         0  \n",
              "373   -0.212155    0.532592         0  \n",
              "..          ...         ...       ...  \n",
              "236   -0.212155    0.532592         0  \n",
              "325   -0.212155    0.532592         0  \n",
              "422   -0.212155    0.532592         0  \n",
              "377   -0.212155    0.532592         0  \n",
              "423   -0.212155    0.532592         0  \n",
              "\n",
              "[214 rows x 10 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "no_diabetes_undersampled = resample(no_survived, \n",
        "                                    replace=False, \n",
        "                                    n_samples = len(survived),\n",
        "                                    random_state=0)\n",
        "no_diabetes_undersampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>2.131931</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.148363</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-0.798490</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.485413</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>0.806264</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>5.358478</td>\n",
              "      <td>0.087483</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>0.178317</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.482720</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>0.892485</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>-0.100771</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.483244</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>0.178317</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.077452</td>\n",
              "      <td>2.149663</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>-1.877611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>0.387633</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>8.572376</td>\n",
              "      <td>2.149663</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>-1.877611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>-0.314064</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>1.434212</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>0.661839</td>\n",
              "      <td>-0.158236</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>-1.520614</td>\n",
              "      <td>-0.752318</td>\n",
              "      <td>1.503984</td>\n",
              "      <td>-0.554683</td>\n",
              "      <td>-0.512321</td>\n",
              "      <td>-0.148363</td>\n",
              "      <td>-0.465189</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>0.532592</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>-0.314064</td>\n",
              "      <td>1.329225</td>\n",
              "      <td>-1.845069</td>\n",
              "      <td>0.503177</td>\n",
              "      <td>1.835999</td>\n",
              "      <td>0.121442</td>\n",
              "      <td>2.149663</td>\n",
              "      <td>-0.212155</td>\n",
              "      <td>-1.877611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>428 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pclass       Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
              "315 -1.520614 -0.752318  2.131931 -0.554683 -0.512321 -0.148363   -0.465189   \n",
              "440  0.892485  1.329225 -0.798490 -0.554683 -0.512321 -0.485413   -0.465189   \n",
              "25   0.892485  1.329225  0.806264 -0.554683  5.358478  0.087483   -0.465189   \n",
              "109  0.892485 -0.752318  0.178317 -0.554683 -0.512321 -0.482720   -0.465189   \n",
              "373  0.892485 -0.752318 -0.100771 -0.554683 -0.512321 -0.483244   -0.465189   \n",
              "..        ...       ...       ...       ...       ...       ...         ...   \n",
              "525 -1.520614 -0.752318  0.178317 -0.554683 -0.512321 -0.077452    2.149663   \n",
              "526 -1.520614  1.329225  0.387633 -0.554683 -0.512321  8.572376    2.149663   \n",
              "527 -0.314064  1.329225  1.434212 -0.554683  0.661839 -0.158236   -0.465189   \n",
              "531 -1.520614 -0.752318  1.503984 -0.554683 -0.512321 -0.148363   -0.465189   \n",
              "532 -0.314064  1.329225 -1.845069  0.503177  1.835999  0.121442    2.149663   \n",
              "\n",
              "     Embarked_Q  Embarked_S  Survived  \n",
              "315   -0.212155    0.532592         0  \n",
              "440   -0.212155    0.532592         0  \n",
              "25    -0.212155    0.532592         0  \n",
              "109   -0.212155    0.532592         0  \n",
              "373   -0.212155    0.532592         0  \n",
              "..          ...         ...       ...  \n",
              "525   -0.212155   -1.877611         1  \n",
              "526   -0.212155   -1.877611         1  \n",
              "527   -0.212155    0.532592         1  \n",
              "531   -0.212155    0.532592         1  \n",
              "532   -0.212155   -1.877611         1  \n",
              "\n",
              "[428 rows x 10 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_under = pd.concat([no_diabetes_undersampled, survived])\n",
        "train_under"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "survived_plt = train_under[\"Survived\"].value_counts()\n",
        "survived_plt.plot(kind=\"bar\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we have the same amount of observations for both survived and not_survived. Let's see how it can impact our model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Separating our features from our target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_under = train_under.drop(columns = [\"Survived\"])\n",
        "y_train_under = train_under[\"Survived\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_under, y_train_under)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.83       104\n",
            "           1       0.75      0.77      0.76        74\n",
            "\n",
            "    accuracy                           0.80       178\n",
            "   macro avg       0.79      0.79      0.79       178\n",
            "weighted avg       0.80      0.80      0.80       178\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\frede\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pred = log_reg.predict(X_test_scaled)\n",
        "print(classification_report(y_pred = pred, y_true = y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SMOTE utilizes KNN approach to generate synthetic samples for the minority class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SMOTE comes from a different package - **imblearn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we need to create a SMOTE object in order to balance our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **sampling_strategy** - corresponds to the ratio of the number of samples in the minority class over the number of samples in the majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state = 1,sampling_strategy=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_sm,y_train_sm = sm.fit_resample(X_train_scaled,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now lets train our model, to see if get any improvements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train_sm, y_train_sm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.82       104\n",
            "           1       0.74      0.76      0.75        74\n",
            "\n",
            "    accuracy                           0.79       178\n",
            "   macro avg       0.78      0.78      0.78       178\n",
            "weighted avg       0.79      0.79      0.79       178\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = log_reg.predict(X_test_scaled)\n",
        "print(classification_report(y_pred = pred, y_true = y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
